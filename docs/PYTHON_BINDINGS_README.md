# LiveTable Rust - Python Bindings

üéâ **Python APIs for the Rust-powered table implementation!**

This package exposes the high-performance Rust implementation of LiveTable tables to Python, giving you blazing-fast table operations with a natural Pythonic API.

## ‚úÖ Status: FULLY WORKING

All major features are implemented and tested!

## Installation

### From Source

```bash
# Install maturin if you haven't already
pip install maturin

# Build and install the package
maturin build --release
pip install target/wheels/livetable-0.1.0-*.whl
```

### Quick Test

```python
import livetable

# Create a table
schema = livetable.Schema([
    ("id", livetable.ColumnType.INT32, False),
    ("name", livetable.ColumnType.STRING, False),
])
table = livetable.Table("users", schema)

# Add data
table.append_row({"id": 1, "name": "Alice"})
print(table[0])  # {'id': 1, 'name': 'Alice'} - indexing support
print(table.get_row(0))  # Same as above
```

## Features

### ‚úÖ Core Table Operations

- **Create tables** with strongly-typed schemas
- **CRUD operations**: append, insert, delete, update
- **Query data**: get rows, get individual values
- **NULL support**: nullable columns work seamlessly

```python
# Create schema
schema = livetable.Schema([
    ("id", livetable.ColumnType.INT32, False),       # Not nullable
    ("name", livetable.ColumnType.STRING, False),    # Not nullable
    ("age", livetable.ColumnType.INT32, True),       # Nullable
    ("score", livetable.ColumnType.FLOAT64, False),  # Not nullable
])

table = livetable.Table("users", schema)

# Add data
table.append_row({"id": 1, "name": "Alice", "age": 30, "score": 95.5})
table.append_row({"id": 2, "name": "Bob", "age": None, "score": 87.0})

# Read data
row = table.get_row(0)
name = table.get_value(0, "name")

# Update data
table.set_value(1, "age", 25)

# Delete row
table.delete_row(1)
```

### ‚úÖ Filter Views

Create filtered views using Python lambda functions:

```python
# Filter with lambda
adults = table.filter(lambda row: row.get("age") and row["age"] >= 18)

# Views are live - they reflect changes to the underlying table
print(f"Found {len(adults)} adults")

for i in range(len(adults)):
    row = adults.get_row(i)
    print(f"{row['name']}: {row['age']} years old")
```

### ‚úÖ Expression-Based Filtering

For faster filtering, use string expressions instead of lambdas (2x faster):

```python
# Expression-based filter - returns list of matching row indices
indices = table.filter_expr("score >= 90 AND name != 'Test'")

# Supported operators:
# - Comparisons: =, !=, <, >, <=, >=
# - Logical: AND, OR, NOT
# - Null checks: IS NULL, IS NOT NULL
# - Parentheses for grouping

# Examples:
indices = table.filter_expr("age >= 18")
indices = table.filter_expr("status = 'active' AND score > 80")
indices = table.filter_expr("(age < 20 OR age > 60) AND country = 'USA'")
indices = table.filter_expr("email IS NOT NULL")
indices = table.filter_expr("NOT (category = 'test')")

# Use the indices to access rows
for idx in indices:
    row = table.get_row(idx)
    print(f"{row['name']}: {row['score']}")
```

**Performance:** Expression filtering is ~2x faster than lambda filtering because the expression is parsed and evaluated entirely in Rust without Python callback overhead.

### ‚úÖ Projection Views

Select specific columns:

```python
# Select only specific columns
public_data = table.select(["id", "name"])

print(f"Columns: {public_data.column_names()}")  # ['id', 'name']
row = public_data.get_row(0)  # Only has 'id' and 'name' fields
```

### ‚úÖ Computed Views

Add computed columns with lambda functions:

```python
# Add a computed column
with_grade = table.add_computed_column(
    "grade",
    lambda row: "A" if row["score"] >= 90 else "B" if row["score"] >= 80 else "C"
)

row = with_grade.get_row(0)
print(f"{row['name']} scored {row['score']} ‚Üí grade {row['grade']}")
```

### ‚úÖ Aggregations

Simple aggregations and GROUP BY support:

```python
# Simple aggregations on a table
total = table.sum("score")           # Sum of all scores
average = table.avg("score")         # Average (None if empty)
minimum = table.min("score")         # Minimum (None if empty)
maximum = table.max("score")         # Maximum (None if empty)
count = table.count_non_null("score") # Count non-NULL values

# GROUP BY with AggregateView
agg = livetable.AggregateView(
    "scores_by_age",
    table,
    ["age"],  # Group by columns
    [
        ("total", "score", livetable.AggregateFunction.SUM),
        ("avg_score", "score", livetable.AggregateFunction.AVG),
        ("count", "score", livetable.AggregateFunction.COUNT),
        ("min_score", "score", livetable.AggregateFunction.MIN),
        ("max_score", "score", livetable.AggregateFunction.MAX),
    ]
)

# Access aggregated data
for i in range(len(agg)):
    row = agg.get_row(i)
    print(f"Age {row['age']}: total={row['total']}, avg={row['avg_score']}")

# Incremental updates - efficient sync after table changes
table.append_row({"id": 3, "name": "Charlie", "age": 30, "score": 92.0})
agg.sync()  # Updates aggregates incrementally (not full rebuild)
```

### ‚úÖ Join Operations

LEFT and INNER joins with automatic column prefixing:

```python
# Create two tables
users = livetable.Table("users", users_schema)
orders = livetable.Table("orders", orders_schema)

# Add data...
users.append_row({"id": 1, "name": "Alice"})
orders.append_row({"order_id": 101, "user_id": 1, "amount": 99.99})

# LEFT JOIN - all users, matched orders
joined = livetable.JoinView(
    "user_orders",
    users,
    orders,
    "id",        # Column in left table
    "user_id",   # Column in right table
    livetable.JoinType.LEFT
)

# Access joined data
for i in range(len(joined)):
    row = joined.get_row(i)
    # Left table columns: id, name
    # Right table columns: right_order_id, right_user_id, right_amount
    print(f"{row['name']}: {row.get('right_amount', 'no orders')}")

# INNER JOIN - only matching rows
inner_joined = livetable.JoinView(
    "matched",
    users,
    orders,
    "id",
    "user_id",
    livetable.JoinType.INNER
)

# MULTI-COLUMN JOIN - composite keys
# Useful for time-series data, hierarchical data, etc.
sales_schema = livetable.Schema([
    ("year", livetable.ColumnType.INT32, False),
    ("month", livetable.ColumnType.INT32, False),
    ("region", livetable.ColumnType.STRING, False),
    ("sales_amount", livetable.ColumnType.FLOAT64, False),
])
targets_schema = livetable.Schema([
    ("target_year", livetable.ColumnType.INT32, False),
    ("target_month", livetable.ColumnType.INT32, False),
    ("target_region", livetable.ColumnType.STRING, False),
    ("target_amount", livetable.ColumnType.FLOAT64, False),
])

sales = livetable.Table("sales", sales_schema)
targets = livetable.Table("targets", targets_schema)

# Join on multiple columns (composite key)
joined = livetable.JoinView(
    "sales_vs_targets",
    sales,
    targets,
    ["year", "month", "region"],  # Left keys (list)
    ["target_year", "target_month", "target_region"],  # Right keys (list)
    livetable.JoinType.LEFT
)

# Single string key still works (backward compatible)
simple_join = livetable.JoinView("j", t1, t2, "id", "ref_id", livetable.JoinType.INNER)
```

### ‚úÖ Serialization (CSV/JSON)

Export and import tables in CSV and JSON formats:

```python
# Create a table with some data
schema = livetable.Schema([
    ("id", livetable.ColumnType.INT32, False),
    ("name", livetable.ColumnType.STRING, False),
    ("score", livetable.ColumnType.FLOAT64, True),
])
table = livetable.Table("students", schema)
table.append_row({"id": 1, "name": "Alice", "score": 95.5})
table.append_row({"id": 2, "name": "Bob", "score": None})

# Export to CSV string
csv_string = table.to_csv()
# Returns:
# id,name,score
# 1,Alice,95.5
# 2,Bob,

# Export to JSON string
json_string = table.to_json()
# Returns:
# [
#   {"id": 1, "name": "Alice", "score": 95.5},
#   {"id": 2, "name": "Bob", "score": null}
# ]

# Import from CSV (types are auto-inferred)
restored = livetable.Table.from_csv("restored", csv_string)

# Import from JSON
restored = livetable.Table.from_json("restored", json_string)

# Save to file
with open("data.csv", "w") as f:
    f.write(table.to_csv())

# Load from file
with open("data.csv", "r") as f:
    table = livetable.Table.from_csv("my_table", f.read())
```

**Type Inference for CSV:**
- Empty values ‚Üí NULL
- Numbers fitting in i32 ‚Üí INT32
- Larger integers ‚Üí INT64
- Numbers with decimals ‚Üí FLOAT64
- "true"/"false" (case-insensitive) ‚Üí BOOL
- YYYY-MM-DD ‚Üí DATE
- YYYY-MM-DDTHH:MM:SS ‚Üí DATETIME
- Everything else ‚Üí STRING

### ‚úÖ Date and DateTime Types

Native support for dates and timestamps:

```python
from datetime import date, datetime

# Create a table with date and datetime columns
schema = livetable.Schema([
    ("id", livetable.ColumnType.INT32, False),
    ("birth_date", livetable.ColumnType.DATE, False),
    ("created_at", livetable.ColumnType.DATETIME, True),
])
table = livetable.Table("events", schema)

# Add rows with date and datetime objects
table.append_row({
    "id": 1,
    "birth_date": date(1990, 5, 15),
    "created_at": datetime(2024, 1, 15, 10, 30, 0),
})
table.append_row({
    "id": 2,
    "birth_date": date(2000, 12, 25),
    "created_at": None,  # Nullable
})

# Read back as Python date/datetime objects
row = table.get_row(0)
print(row["birth_date"])   # date(1990, 5, 15)
print(row["created_at"])   # datetime(2024, 1, 15, 10, 30)

# Dates before Unix epoch (1970-01-01) are supported
table.append_row({
    "id": 3,
    "birth_date": date(1955, 3, 14),  # Einstein's death
    "created_at": datetime(1969, 7, 20, 20, 17, 0),  # Moon landing
})

# CSV/JSON serialization uses ISO 8601 format
csv = table.to_csv()
# Output includes: 1990-05-15, 2024-01-15T10:30:00

# Import from CSV/JSON auto-detects date/datetime strings
csv_data = "id,date\n1,2023-06-15\n2,1970-01-01"
imported = livetable.Table.from_csv("imported", csv_data)
row = imported.get_row(0)
print(row["date"])  # date(2023, 6, 15)
```

**Accepted input formats:**
- `datetime.date` objects
- `datetime.datetime` objects (time part used for DATETIME, discarded for DATE)
- Integers: days since epoch for DATE, milliseconds since epoch for DATETIME
- ISO 8601 strings in CSV/JSON: `YYYY-MM-DD` or `YYYY-MM-DDTHH:MM:SS`

### ‚úÖ Iterator Protocol

All tables and views support Python's iterator protocol, enabling `for row in table:` syntax:

```python
# Iterate over a table
for row in table:
    print(f"{row['name']}: {row['score']}")

# Works with all view types
filtered = table.filter(lambda r: r["score"] >= 90)
for row in filtered:
    print(f"High scorer: {row['name']}")

# Use with list comprehensions
names = [row["name"] for row in table]

# Use with built-in functions
total = sum(row["score"] for row in table)
sorted_rows = sorted(table, key=lambda r: r["score"])

# Works with enumerate() and zip()
for i, row in enumerate(table):
    print(f"Row {i}: {row['name']}")
```

**Supported types:**
- `Table`
- `FilterView`
- `ProjectionView`
- `ComputedView`
- `JoinView`
- `SortedView`
- `AggregateView`

### ‚úÖ Bulk Operations

Insert multiple rows efficiently with a single call:

```python
# Insert many rows at once
rows = [
    {"id": 1, "name": "Alice", "score": 95.5},
    {"id": 2, "name": "Bob", "score": 87.0},
    {"id": 3, "name": "Charlie", "score": 92.0},
]
count = table.append_rows(rows)  # Returns number of rows inserted

# Much more efficient than calling append_row() in a loop
# Especially for large datasets (1000+ rows)
```

**Benefits:**
- Reduces Python-Rust boundary crossings from N to 1
- Better memory allocation patterns
- Validates all rows before inserting (atomic operation)

### ‚úÖ Pandas DataFrame Interop

Convert between LiveTable and pandas DataFrames:

```python
import pandas as pd
import livetable

# Table ‚Üí DataFrame
df = table.to_pandas()
print(df.describe())  # Use any pandas operations

# DataFrame ‚Üí Table
df = pd.DataFrame({
    "id": [1, 2, 3],
    "name": ["Alice", "Bob", "Charlie"],
    "score": [95.5, 87.0, 92.0],
})
table = livetable.Table.from_pandas("students", df)

# Round-trip preserves data
df_copy = table.to_pandas()
table_copy = livetable.Table.from_pandas("copy", df_copy)
```

**Type mapping:**
- pandas `int64` ‚Üí `INT64`
- pandas `float64` ‚Üí `FLOAT64`
- pandas `object`/`string` ‚Üí `STRING`
- pandas `bool` ‚Üí `BOOL`
- pandas `NaN`/`None` ‚Üí `NULL`

**Note:** Requires pandas to be installed (`pip install pandas`).

## Supported Data Types

| Python Type | LiveTable ColumnType | Rust Type | Notes |
|-------------|----------------|-----------|-------|
| `int` | `ColumnType.INT32` | `i32` | |
| `int` | `ColumnType.INT64` | `i64` | |
| `float` | `ColumnType.FLOAT32` | `f32` | |
| `float` | `ColumnType.FLOAT64` | `f64` | |
| `str` | `ColumnType.STRING` | `String` | |
| `bool` | `ColumnType.BOOL` | `bool` | |
| `datetime.date` | `ColumnType.DATE` | `i32` (days since 1970-01-01) | Stored as ISO 8601 in CSV/JSON |
| `datetime.datetime` | `ColumnType.DATETIME` | `i64` (ms since 1970-01-01) | Stored as ISO 8601 in CSV/JSON |
| `None` | (any nullable column) | `NULL` | |

## API Reference

### Schema

```python
Schema(columns: list[tuple[str, ColumnType, bool]])
```

Create a table schema.

**Parameters:**
- `columns`: List of `(name, type, nullable)` tuples

**Methods:**
- `len()` - Number of columns
- `get_column_names()` - List of column names
- `get_column_index(name)` - Get index by name
- `get_column_info(index)` - Get `(name, type, nullable)` tuple

### Table

```python
Table(name: str, schema: Schema, use_tiered_vector: bool = False)
```

Create a new table.

**Methods:**
- `len()` - Number of rows
- `is_empty()` - Check if table is empty
- `name()` - Get table name
- `column_names()` - Get list of column names
- `append_row(row: dict)` - Add row at end
- `append_rows(rows: list[dict]) -> int` - Add multiple rows at once (bulk insert)
- `insert_row(index: int, row: dict)` - Insert row at position
- `delete_row(index: int)` - Remove row
- `get_value(row: int, column: str)` - Get single value
- `set_value(row: int, column: str, value)` - Set single value
- `get_row(index: int) -> dict` - Get full row as dictionary
- `table[index]` - Same as `get_row(index)` (indexing support)
- `display()` - Get formatted table info
- `filter(predicate: callable) -> FilterView` - Create filtered view
- `filter_expr(expression: str) -> list[int]` - Filter using expression (2x faster)
- `select(columns: list[str]) -> ProjectionView` - Create projection
- `add_computed_column(name: str, fn: callable) -> ComputedView` - Add computed column
- `sum(column: str) -> float` - Sum of numeric column
- `avg(column: str) -> float | None` - Average of numeric column
- `min(column: str) -> float | None` - Minimum of numeric column
- `max(column: str) -> float | None` - Maximum of numeric column
- `count_non_null(column: str) -> int` - Count non-NULL values
- `to_csv() -> str` - Export table to CSV string
- `to_json() -> str` - Export table to JSON string
- `to_pandas() -> pandas.DataFrame` - Export table to pandas DataFrame
- `Table.from_csv(name: str, csv: str) -> Table` - Import from CSV (static method)
- `Table.from_json(name: str, json: str) -> Table` - Import from JSON (static method)
- `Table.from_pandas(name: str, df: pandas.DataFrame) -> Table` - Import from DataFrame (static method)

### FilterView

```python
FilterView(table: Table, predicate: callable)
```

Filtered view of a table.

**Methods:**
- `len()` - Number of matching rows
- `get_row(index: int) -> dict` - Get row
- `view[index]` - Same as `get_row(index)` (indexing support)
- `get_value(row: int, column: str)` - Get value
- `refresh()` - Rebuild filter (if table changed)

### ProjectionView

```python
ProjectionView(table: Table, columns: list[str])
```

View with selected columns only.

**Methods:**
- `len()` - Number of rows
- `column_names()` - Selected columns
- `get_row(index: int) -> dict` - Get row (only selected columns)
- `view[index]` - Same as `get_row(index)` (indexing support)
- `get_value(row: int, column: str)` - Get value

### ComputedView

```python
ComputedView(table: Table, computed_column_name: str, compute_fn: callable)
```

View with an additional computed column.

**Methods:**
- `len()` - Number of rows
- `column_names()` - All columns (including computed)
- `get_row(index: int) -> dict` - Get row with computed value
- `view[index]` - Same as `get_row(index)` (indexing support)
- `get_value(row: int, column: str)` - Get value

### JoinView

```python
JoinView(
    name: str,
    left_table: Table,
    right_table: Table,
    left_keys: str | list[str],   # Single key or list for composite keys
    right_keys: str | list[str],  # Single key or list for composite keys
    join_type: JoinType
)
```

Join two tables on matching columns. Supports both single-column and multi-column (composite key) joins.

**Multi-column join example:**
```python
joined = livetable.JoinView("j", sales, targets,
    ["year", "month"],           # Left keys
    ["target_year", "target_month"],  # Right keys
    livetable.JoinType.INNER)
```

**Methods:**
- `len()` - Number of joined rows
- `is_empty()` - Check if empty
- `name()` - Get join name
- `get_row(index: int) -> dict` - Get joined row
- `view[index]` - Same as `get_row(index)` (indexing support)
- `get_value(row: int, column: str)` - Get value
- `refresh()` - Rebuild join

**Notes:**
- Right table columns are prefixed with `"right_"` to avoid conflicts
- NULL values in join keys don't match (SQL semantics)
- Key counts must match between left and right

### JoinType

Enum for join types:
- `JoinType.LEFT` - All rows from left, matched from right
- `JoinType.INNER` - Only rows that match in both tables

### AggregateFunction

Enum for aggregation types:
- `AggregateFunction.SUM` - Sum of numeric values
- `AggregateFunction.COUNT` - Count of non-NULL values
- `AggregateFunction.AVG` - Average of numeric values
- `AggregateFunction.MIN` - Minimum numeric value
- `AggregateFunction.MAX` - Maximum numeric value

### AggregateView

```python
AggregateView(
    name: str,
    table: Table,
    group_by: list[str],
    aggregations: list[tuple[str, str, AggregateFunction]]
)
```

GROUP BY view with aggregations.

**Parameters:**
- `name`: View name
- `table`: Source table
- `group_by`: List of columns to group by
- `aggregations`: List of `(result_column, source_column, function)` tuples

**Methods:**
- `len()` - Number of groups
- `get_row(index: int) -> dict` - Get group row with aggregated values
- `view[index]` - Same as `get_row(index)` (indexing support)
- `get_value(row: int, column: str)` - Get single value
- `column_names()` - All columns (group-by + result columns)
- `sync()` - Incremental update after table changes
- `refresh()` - Full rebuild

## Performance

The Rust backend provides significant performance improvements over pure Python:

- **10-100x faster** operations (based on benchmarks)
- **Zero-copy views** - FilterView, ProjectionView don't duplicate data
- **Sub-nanosecond access** for individual operations
- **Efficient joins** - O(N+M) complexity

## Complete Example

See [test_python_bindings.py](test_python_bindings.py) for a comprehensive example covering all features.

```bash
python3 test_python_bindings.py
```

## Building from Source

### Prerequisites

- Rust (install from https://rustup.rs)
- Python 3.8+
- maturin

### Build Steps

```bash
# Install maturin
pip install maturin

# Build release wheel
maturin build --release

# Install
pip install target/wheels/livetable-*.whl

# Or for development (requires virtualenv)
python3 -m venv .venv
source .venv/bin/activate
maturin develop
```

### For Python 3.14

Python 3.14 requires forward compatibility flag:

```bash
env PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1 maturin build --release
```

## Implementation Details

- **Language**: Rust with PyO3 bindings
- **Lines of code**: ~700 lines of bindings
- **PyO3 version**: 0.22
- **Rust features**: `Rc<RefCell<>>` for shared ownership, type-safe conversions

## Troubleshooting

### Type Errors

Make sure you're using the correct types:

```python
# ‚úì Correct
table.append_row({"id": 1, "score": 95.5})

# ‚úó Wrong - will fail if id is INT32
table.append_row({"id": "1", "score": 95.5})
```

### NULL Values

Use Python `None` for NULL values in nullable columns:

```python
# ‚úì Correct
table.append_row({"id": 1, "age": None})

# Check for None
row = table.get_row(0)
if row.get("age") is not None:
    print(f"Age: {row['age']}")
```

### Join Column Naming

Right table columns are prefixed with `"right_"`:

```python
row = joined.get_row(0)
user_id = row["id"]              # From left table
order_id = row["right_order_id"] # From right table (prefixed!)
amount = row["right_amount"]     # From right table (prefixed!)
```

## Comparison with Pure Python

| Feature | Python (livetable) | Rust (livetable) |
|---------|--------------|-----------------|
| Speed | Baseline | 10-100x faster |
| Memory | High (Python objects) | Low (Rust structs) |
| Type Safety | Runtime | Compile-time + Runtime |
| API | Pythonic | Pythonic (same!) |
| Installation | `import table` | `pip install livetable` |

## Future Enhancements

Potential additions:
- [x] ~~GroupBy/Aggregation support~~ ‚úÖ **DONE!**
- [x] ~~CSV/JSON Serialization~~ ‚úÖ **DONE!**
- [x] ~~Iterator protocol support~~ ‚úÖ **DONE!**
- [x] ~~Pandas DataFrame interop~~ ‚úÖ **DONE!**
- [x] ~~Bulk operations (append_rows)~~ ‚úÖ **DONE!**
- [x] ~~Multi-column joins~~ ‚úÖ **DONE!**
- [x] ~~Expression-based filtering~~ ‚úÖ **DONE!**
- [ ] RIGHT and FULL OUTER joins

## Contributing

This is part of the livetable project. See the main README for contribution guidelines.

## License

MIT

---

**Built with ‚ù§Ô∏è using Rust and PyO3**
